{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('deepLearning')",
   "display_name": "Python 3.8.6 64-bit ('deepLearning')",
   "metadata": {
    "interpreter": {
     "hash": "fabda35dea35b80cd6431b98e91ddb3db65b956456306a434410485951fd57f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Preprocessing\n",
    "### import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np #only numpy arrays can be the input of keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "### Train set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "\n",
    "#'training_set = dataset_train.iloc[:, 1].values' would only give us a 1D array\n",
    "training_set = dataset_train.iloc[:, 1:2].values #gives us one column for open prices"
   ]
  },
  {
   "source": [
    "### Feature scaling with Normalization: (X-min)/(max-min)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set) # it is recommended to keep the original set separate"
   ]
  },
  {
   "source": [
    "### Creating a data structure with n timesteps and 1 output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 120 # number of timesteps\n",
    "\n",
    "X_train = [] # will contain lists of previous stock prices\n",
    "y_train = [] # will contain the next stock price\n",
    "\n",
    "\n",
    "# start at 'n_timesteps' so that the first element actually has n previous prices\n",
    "for i in range(n_timesteps, training_set_scaled.shape[0]):\n",
    "    X_train.append(training_set_scaled[i-n_timesteps:i, 0]) # adds a list of n previous prices\n",
    "    y_train.append(training_set_scaled[i, 0]) # adds the current price\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "source": [
    "### Reshaping to add more indicators"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#for RNNs, the dimensions are (batch_size, timesteps, number of indicators). Here the only indicator is open price"
   ]
  },
  {
   "source": [
    "# Building the RNN\n",
    "### import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout # to prevent overfiting"
   ]
  },
  {
   "source": [
    "### Initialising the RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential() #the RNN\n",
    "#Tip: A classifier predicts categories. A regressor predicts a continuous value."
   ]
  },
  {
   "source": [
    "### Adding the first LSTM layer and some Dropout regularisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM( units = 60, return_sequences= True, input_shape = (X_train.shape[1], 1)))\n",
    "# units : neurons\n",
    "# return_sequences: set to True if you are going to add more LSTM layers\n",
    "#input_shape: only include the dimensions 'timesteps' and 'indicators' of X_train. The first dimension is already included\n",
    "\n",
    "regressor.add(Dropout(.2))\n",
    "#to prevent overfitting during regression, drop a part of the neurons during each iteration\n",
    "#using a rate\n"
   ]
  },
  {
   "source": [
    "### Adding more LSTM layers and Dropout regularizations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM( units = 60, return_sequences= True)) # we no longer need the input shape for following layers\n",
    "regressor.add(Dropout(.2))\n",
    "\n",
    "regressor.add(LSTM( units = 60, return_sequences= True))\n",
    "regressor.add(Dropout(.2))\n",
    "\n",
    "regressor.add(LSTM( units = 60, return_sequences= True))\n",
    "regressor.add(Dropout(.2))\n",
    "\n",
    "regressor.add(LSTM( units = 60, return_sequences= True))\n",
    "regressor.add(Dropout(.2))\n",
    "\n",
    "regressor.add(LSTM( units = 60, return_sequences= False)) #False become the next layer is not LSTM\n",
    "regressor.add(Dropout(.2))\n"
   ]
  },
  {
   "source": [
    "### Adding the output layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "source": [
    "### Compiling the RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= 'adam', loss= 'mean_squared_error')"
   ]
  },
  {
   "source": [
    "Fitting the RNN to the Training set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train, epochs= 100, batch_size= 32)"
   ]
  },
  {
   "source": [
    "# Making predictions and Visualising the results "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "source": [
    "### getting the predicted stock price"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On thing to point out is that we will need the previous stock prices of of the first items of the test set.\n",
    "# Those previous prices must be obtained from the training set\n",
    "\n",
    "# Also, we cannot change the test values. Therefore:\n",
    "# we will concatonate the original dataframes for training and test set to obtain our missing values,\n",
    "# and that's what we will scale.\n",
    "\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']), axis = 0) #we are only keeping the 'Open column\n",
    "# the second argument is the axis. We want to link the values in one column, so it's a vertical concatonation (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: for each time T we're predicting, we need the n previous prices\n",
    "\n",
    "#Here, we need n previous prices before the one we're predicting\n",
    "# lower_bound = total index - total of the test set - n\n",
    "lower_bound = len(dataset_total) - len(dataset_test) - n_timesteps\n",
    "\n",
    "#Upper_bound is the last stock price before the last day, so simply the last item of dataset_total \n",
    "inputs = dataset_total[lower_bound:].values # add .values to make it a numpy array\n",
    "\n",
    "#because we did not use 'iloc', we need to reshape the numpy array\n",
    "inputs = inputs.reshape(-1,1)"
   ]
  },
  {
   "source": [
    "#### reshape(-1,1) \n",
    "The criterion for the new shape is that it must be compatible with the original shape. **-1** means that the dimension is unknown and we are relying on the function to figure out the shape by itself\n",
    "\n",
    "For example, **(-1,1)** means that the new shape must have one column and the number of rows is a dependent variable (rows = total / 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sc.transform(inputs) # scaling our inputs\n",
    "\n",
    "X_test = []\n",
    "for i in range(n_timesteps, inputs.shape[0]): # the range will be the 20 values we're trying to predict\n",
    "    X_test.append(inputs[i-n_timesteps:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = X_test.reshape( X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test) # predict the stock prices\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) # reverse the scaling to obtain the actual predicted prices"
   ]
  },
  {
   "source": [
    "### Visualising the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding data to the plot\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Actual Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend() # to display legends\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Evaluating the RNN\n",
    "We can use the **Root Mean Squared Error (RMSE)** to check how close our predicted results are close to the actual prices. \n",
    "However, keep in mind that RMSE is not that most useful in this case since we're more concerned with the movements of the values instead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price,predicted_stock_price))\n",
    "\n",
    "# dividing rmse by the average of values to get a relative error instead of absolute error\n",
    "average_of_stock = (max(real_stock_price) + min(real_stock_price))/2\n",
    "range_of_stock = max(real_stock_price)[0] - min(real_stock_price)[0]\n",
    "relative_rmse = rmse/range_of_stock\n",
    "\n",
    "print (f\"RMSE: {rmse:5.2f}\\nRelative RMSE: {relative_rmse:5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}